import "https://deno.land/x/xhr@0.1.0/mod.ts";
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.49.8';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

serve(async (req) => {
  // Handle CORS preflight requests
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const OPENAI_API_KEY = Deno.env.get('OPENAI_API_KEY');
    const ASSEMBLYAI_API_KEY = Deno.env.get('ASSEMBLYAI_API_KEY');
    const SUPABASE_URL = Deno.env.get('SUPABASE_URL');
    const SUPABASE_SERVICE_ROLE_KEY = Deno.env.get('SUPABASE_SERVICE_ROLE_KEY');
    
    console.log('üöÄ Starting process-meeting-audio function');
    console.log('üîê Environment check:', {
      hasOpenAI: !!OPENAI_API_KEY,
      hasAssemblyAI: !!ASSEMBLYAI_API_KEY,
      hasSupabaseURL: !!SUPABASE_URL,
      hasSupabaseKey: !!SUPABASE_SERVICE_ROLE_KEY,
      openAILength: OPENAI_API_KEY?.length || 0,
      assemblyAILength: ASSEMBLYAI_API_KEY?.length || 0,
      supabaseURL: SUPABASE_URL || 'MISSING'
    });
    
    if (!SUPABASE_URL || !SUPABASE_SERVICE_ROLE_KEY) {
      console.error('‚ùå Missing Supabase environment variables');
      throw new Error('Missing required Supabase environment variables');
    }
    
    if (!OPENAI_API_KEY) {
      console.error('‚ùå OpenAI API key not configured');
      return new Response(JSON.stringify({ 
        success: false, 
        error: 'OpenAI API key not configured - Audio processing unavailable'
      }), {
        status: 400,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      });
    }

    console.log('‚úÖ All environment variables validated');
    const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY);
    
    console.log('üìã Reading request body...');
    const requestBody = await req.json();
    const { filePath, meetingId, meetingData, audio, userId } = requestBody;
    
    console.log('üìù Request data received:', {
      hasFilePath: !!filePath,
      filePath: filePath || 'NOT_PROVIDED',
      hasMeetingId: !!meetingId,
      meetingId: meetingId || 'NOT_PROVIDED',
      hasAudio: !!audio,
      audioLength: audio?.length || 0,
      hasUserId: !!userId,
      userId: userId || 'NOT_PROVIDED',
      hasMeetingData: !!meetingData,
      meetingDataKeys: meetingData ? Object.keys(meetingData) : [],
      rawBodyKeys: Object.keys(requestBody)
    });

    console.log('üé¨ Processing meeting audio for meeting:', meetingId);
    console.log('üîß Parameters received:', { 
      hasFilePath: !!filePath, 
      hasMeetingId: !!meetingId, 
      hasAudio: !!audio, 
      hasUserId: !!userId,
      meetingDataKeys: meetingData ? Object.keys(meetingData) : []
    });

    // Get userId - enhanced resolution with better error handling
    let resolvedUserId = userId || meetingData?.userId || meetingData?.user_id;
    
    if (!resolvedUserId) {
      console.log('üìã UserId not provided, fetching from meeting record...');
      const { data: meetingRecord, error: meetingError } = await supabase
        .from('meeting_recordings')
        .select('user_id')
        .eq('id', meetingId)
        .single();
      
      if (meetingError) {
        console.error('‚ùå Failed to fetch meeting record:', meetingError);
        throw new Error(`Failed to fetch meeting record: ${meetingError.message}`);
      }
      
      resolvedUserId = meetingRecord.user_id;
      console.log('‚úÖ Resolved userId from meeting record:', resolvedUserId);
    } else {
      console.log('‚úÖ Using provided userId:', resolvedUserId);
    }

    let audioBlob;
    let transcriptText = '';

    // Handle different input types
    if (filePath) {
      // File-based processing (preferred for large files)
      console.log('üéµ Processing audio file from storage:', filePath);
      
      try {
        // Get the audio file from storage with explicit bucket and path
        const { data: fileData, error: downloadError } = await supabase.storage
          .from('voice-recordings')
          .download(filePath);
        
        if (downloadError) {
          console.error('‚ùå Storage download error:', downloadError);
          throw new Error(`Failed to download audio file: ${downloadError.message}`);
        }
        
        if (!fileData) {
          throw new Error('No audio file data received from storage');
        }
        
        console.log('‚úÖ Audio file downloaded successfully, size:', fileData.size, 'bytes');
        audioBlob = fileData;
      } catch (storageError) {
        console.error('‚ùå Storage access failed:', storageError);
        throw new Error(`Storage access error: ${storageError instanceof Error ? storageError.message : 'Unknown storage error'}`);
      }
    } else if (audio) {
      // Direct audio data (base64)
      console.log('üéµ Processing direct audio data');
      
      // Convert base64 to blob
      const binaryString = atob(audio);
      const bytes = new Uint8Array(binaryString.length);
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i);
      }
      audioBlob = new Blob([bytes], { type: 'audio/webm' });
    } else {
      throw new Error('No audio file path or data provided');
    }

    // Transcribe audio using AssemblyAI (or OpenAI Whisper)
    if (ASSEMBLYAI_API_KEY) {
      console.log('üé§ Using AssemblyAI for transcription');
      
      try {
        // Test AssemblyAI API connection
        console.log('üé§ Using AssemblyAI for transcription');
        console.log('üîë AssemblyAI Key format check:', {
          keyLength: ASSEMBLYAI_API_KEY?.length || 0,
          keyPrefix: ASSEMBLYAI_API_KEY?.substring(0, 10) || 'none',
          keyType: typeof ASSEMBLYAI_API_KEY
        });
        
        // Upload file to AssemblyAI
        console.log('üì§ Uploading to AssemblyAI...');
        const uploadResponse = await fetch('https://api.assemblyai.com/v2/upload', {
          method: 'POST',
          headers: {
            'Authorization': ASSEMBLYAI_API_KEY,
            'Content-Type': 'application/octet-stream'
          },
          body: audioBlob
        });

        console.log('üì§ AssemblyAI upload response:', {
          status: uploadResponse.status,
          statusText: uploadResponse.statusText,
          ok: uploadResponse.ok,
          headers: Object.fromEntries(uploadResponse.headers.entries())
        });

        if (!uploadResponse.ok) {
          const errorText = await uploadResponse.text();
          console.log('‚ùå AssemblyAI upload failed:', errorText);
          console.log('üîç Debug info:', {
            requestHeaders: {
              'Authorization': `${ASSEMBLYAI_API_KEY?.substring(0, 10)}...`,
              'Content-Type': 'application/octet-stream'
            },
            bodySize: audioBlob.size,
            bodyType: audioBlob.type
          });
          throw new Error(`AssemblyAI upload failed: ${uploadResponse.status} ${uploadResponse.statusText} - ${errorText}`);
        }
        
        const uploadData = await uploadResponse.json();
        console.log('‚úÖ Upload successful, URL received:', !!uploadData.upload_url);
        
        // Request transcription
        console.log('üéØ Requesting transcription...');
        const transcriptionResponse = await fetch('https://api.assemblyai.com/v2/transcript', {
          method: 'POST',
          headers: {
            'Authorization': ASSEMBLYAI_API_KEY,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({
            audio_url: uploadData.upload_url,
            speaker_labels: true
          })
        });
        
        console.log('üéØ Transcription request response:', {
          status: transcriptionResponse.status,
          statusText: transcriptionResponse.statusText,
          ok: transcriptionResponse.ok
        });
        
        if (!transcriptionResponse.ok) {
          const errorText = await transcriptionResponse.text();
          console.error('‚ùå AssemblyAI transcription request failed:', errorText);
          throw new Error(`AssemblyAI transcription failed: ${transcriptionResponse.status} ${transcriptionResponse.statusText} - ${errorText}`);
        }
        
        const transcriptionData = await transcriptionResponse.json();
        const transcriptId = transcriptionData.id;
        console.log('‚úÖ Transcription job started, ID:', transcriptId);
        
        // Poll for completion (simplified - in production use webhooks)
        let attempts = 0;
        const maxAttempts = 30; // 5 minutes max
        
        console.log('‚è≥ Polling for transcription completion...');
        while (attempts < maxAttempts) {
          console.log(`üîÑ Polling attempt ${attempts + 1}/${maxAttempts}...`);
          
          const statusResponse = await fetch(`https://api.assemblyai.com/v2/transcript/${transcriptId}`, {
            headers: { 
              'Authorization': ASSEMBLYAI_API_KEY
            }
          });
          
          console.log('üìä Status check response:', {
            status: statusResponse.status,
            ok: statusResponse.ok
          });
          
          if (!statusResponse.ok) {
            console.error('‚ùå Status check failed:', statusResponse.statusText);
            throw new Error(`Status check failed: ${statusResponse.statusText}`);
          }
          
          const statusData = await statusResponse.json();
          console.log('üìä Transcription status:', {
            status: statusData.status,
            hasText: !!statusData.text,
            textLength: statusData.text?.length || 0
          });
          
          if (statusData.status === 'completed') {
            transcriptText = statusData.text;
            console.log('‚úÖ Transcription completed successfully!');
            break;
          } else if (statusData.status === 'error') {
            console.error('‚ùå Transcription error:', statusData.error);
            throw new Error(`Transcription failed: ${statusData.error}`);
          }
          
          console.log(`‚è≥ Status: ${statusData.status}, waiting 10 seconds...`);
          await new Promise(resolve => setTimeout(resolve, 10000)); // Wait 10 seconds
          attempts++;
        }
        
        if (!transcriptText) {
          console.error('‚ùå Transcription timed out after', maxAttempts, 'attempts');
          throw new Error('Transcription timed out');
        }
      } catch (assemblyError) {
        console.error('‚ùå AssemblyAI processing failed:', assemblyError);
        throw new Error(`AssemblyAI processing failed: ${assemblyError instanceof Error ? assemblyError.message : 'Unknown error'}`);
      }
    } else {
      // Fallback to OpenAI Whisper
      console.log('üé§ Using OpenAI Whisper for transcription');
      
      try {
        const formData = new FormData();
        formData.append('file', audioBlob, 'audio.webm');
        formData.append('model', 'whisper-1');
        
        console.log('üì§ Sending to OpenAI Whisper...');
        const transcriptionResponse = await fetch('https://api.openai.com/v1/audio/transcriptions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${OPENAI_API_KEY}`,
          },
          body: formData
        });
        
        console.log('üé§ Whisper response:', {
          status: transcriptionResponse.status,
          ok: transcriptionResponse.ok
        });
        
        if (!transcriptionResponse.ok) {
          const errorText = await transcriptionResponse.text();
          console.error('‚ùå Whisper transcription failed:', errorText);
          throw new Error(`Whisper transcription failed: ${transcriptionResponse.status} - ${errorText}`);
        }
        
        const transcriptionData = await transcriptionResponse.json();
        transcriptText = transcriptionData.text;
        console.log('‚úÖ Whisper transcription completed');
      } catch (whisperError) {
        console.error('‚ùå OpenAI Whisper processing failed:', whisperError);
        throw new Error(`Whisper processing failed: ${whisperError instanceof Error ? whisperError.message : 'Unknown error'}`);
      }
    }

    console.log('üéØ Transcription completed:', {
      length: transcriptText.length,
      preview: transcriptText.substring(0, 100) + (transcriptText.length > 100 ? '...' : '')
    });

    // Update meeting record with transcript
    console.log('üíæ Updating meeting record with transcript...');
    const { error: updateError } = await supabase
      .from('meeting_recordings')
      .update({ 
        transcript: transcriptText,
        processing_status: 'completed',
        processing_completed_at: new Date().toISOString()
      })
      .eq('id', meetingId);

    if (updateError) {
      console.error('‚ùå Error updating meeting record:', updateError);
    } else {
      console.log('‚úÖ Meeting record updated successfully');
    }

    // Extract ACTs using the existing function with resolved userId
    console.log('üéØ Extracting ACTs with userId:', resolvedUserId);
    const { data: extractionData, error: extractionError } = await supabase.functions.invoke('extract-acts-incremental', {
      body: {
        transcript: transcriptText,
        meetingId: meetingId,
        userId: resolvedUserId
      }
    });

    if (extractionError) {
      console.error('‚ùå Error extracting ACTs:', extractionError);
      console.error('üîç Extraction error details:', JSON.stringify(extractionError, null, 2));
    } else {
      console.log('‚úÖ ACT extraction successful, found:', extractionData?.actionsCount || 0, 'actions');
    }

    console.log('üéâ Processing completed successfully');

    return new Response(JSON.stringify({ 
      success: true, 
      transcriptLength: transcriptText.length,
      actionsExtracted: extractionData?.actionsCount || 0,
      meetingId: meetingId
    }), {
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });

  } catch (error) {
    console.error('üí• CRITICAL ERROR in process-meeting-audio function:', error);
    console.error('üîç Error details:', {
      name: error instanceof Error ? error.name : 'Unknown',
      message: error instanceof Error ? error.message : String(error),
      stack: error instanceof Error ? error.stack : 'No stack trace'
    });
    
    // Update meeting record with error
    try {
      console.log('üíæ Attempting to update meeting record with error status...');
      const body = await req.clone().json();
      if (body.meetingId) {
        const supabase = createClient(
          Deno.env.get('SUPABASE_URL')!,
          Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
        );
        
        const { error: updateError } = await supabase
          .from('meeting_recordings')
          .update({ 
            processing_status: 'error',
            processing_error: error instanceof Error ? error.message : 'Unknown error occurred'
          })
          .eq('id', body.meetingId);
          
        if (updateError) {
          console.error('‚ùå Failed to update meeting with error status:', updateError);
        } else {
          console.log('‚úÖ Meeting record updated with error status');
        }
      }
    } catch (updateError) {
      console.error('‚ùå Error updating meeting with error status:', updateError);
    }
    
    const errorResponse = {
      error: error instanceof Error ? error.message : 'An unexpected error occurred',
      timestamp: new Date().toISOString(),
      function: 'process-meeting-audio'
    };
    
    console.error('üö® Returning error response:', errorResponse);
    
    return new Response(JSON.stringify(errorResponse), {
      status: 500,
      headers: { ...corsHeaders, 'Content-Type': 'application/json' },
    });
  }
});